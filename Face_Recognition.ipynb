{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6bX8taRUm5ElDx8e3/OWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MikeManzi/multimodel-data-preprocessing/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "gZnXs4e9g_MZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder # Import LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "class FacialRecognitionModel:\n",
        "    \"\"\"\n",
        "    Improved Facial Recognition Model for user authentication\n",
        "    with PCA, feature selection, and hybrid model selection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_type='hybrid'):\n",
        "        self.model_type = model_type\n",
        "        self.model = None\n",
        "        self.scaler = StandardScaler()\n",
        "        self.pca = None\n",
        "        self.selector = None\n",
        "        self.label_encoder = LabelEncoder() # Initialize LabelEncoder\n",
        "\n",
        "    def preprocess_data(self, X, y):\n",
        "        print(f\"\\nLoaded dataset with {X.shape[0]} rows and {X.shape[1]} columns.\")\n",
        "\n",
        "        # Encode string labels to numerical labels\n",
        "        y_encoded = self.label_encoder.fit_transform(y)\n",
        "\n",
        "        # Handle class imbalance\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_res, y_res = smote.fit_resample(X, y_encoded) # Use encoded y\n",
        "        print(f\"Balanced dataset: {X_res.shape[0]} samples after SMOTE.\")\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X_res)\n",
        "\n",
        "        # Select top K features\n",
        "        print(\"Applying SelectKBest feature selection...\")\n",
        "        self.selector = SelectKBest(score_func=f_classif, k=min(300, X_scaled.shape[1]))\n",
        "        X_selected = self.selector.fit_transform(X_scaled, y_res) # Use encoded y\n",
        "\n",
        "        # Apply PCA to reduce noise and redundancy\n",
        "        print(\"Applying PCA dimensionality reduction...\")\n",
        "        self.pca = PCA(n_components=0.95, random_state=42)\n",
        "        X_reduced = self.pca.fit_transform(X_selected)\n",
        "\n",
        "        return X_reduced, y_res\n",
        "\n",
        "    def train(self, X, y):\n",
        "        X_proc, y_proc = self.preprocess_data(X, y)\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_proc, y_proc, test_size=0.2, random_state=42, stratify=y_proc\n",
        "        )\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"Training Facial Recognition Model ({self.model_type})\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        if self.model_type == 'hybrid':\n",
        "            # Compare RandomForest and XGBoost\n",
        "            rf = RandomForestClassifier(random_state=42)\n",
        "            xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "            rf_cv = np.mean(cross_val_score(rf, X_train, y_train, cv=5))\n",
        "            xgb_cv = np.mean(cross_val_score(xgb, X_train, y_train, cv=5))\n",
        "\n",
        "            print(f\"RF CV Accuracy: {rf_cv:.4f} | XGB CV Accuracy: {xgb_cv:.4f}\")\n",
        "            best_model = rf if rf_cv >= xgb_cv else xgb\n",
        "\n",
        "            # Fine-tune RandomForest if chosen\n",
        "            if isinstance(best_model, RandomForestClassifier):\n",
        "                print(\"Running GridSearchCV for RandomForest tuning...\")\n",
        "                param_grid = {\n",
        "                    'n_estimators': [100, 200, 300],\n",
        "                    'max_depth': [10, 20, None],\n",
        "                    'min_samples_split': [2, 5, 10]\n",
        "                }\n",
        "                grid = GridSearchCV(best_model, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "                grid.fit(X_train, y_train)\n",
        "                self.model = grid.best_estimator_\n",
        "                print(f\"Best RF Params: {grid.best_params_}\")\n",
        "            else:\n",
        "                self.model = best_model.fit(X_train, y_train)\n",
        "\n",
        "        else:\n",
        "            if self.model_type == 'random_forest':\n",
        "                self.model = RandomForestClassifier(random_state=42).fit(X_train, y_train)\n",
        "            elif self.model_type == 'xgboost':\n",
        "                self.model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42).fit(X_train, y_train)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported model type\")\n",
        "\n",
        "        y_pred = self.model.predict(X_test)\n",
        "        y_prob = self.model.predict_proba(X_test)\n",
        "        self.evaluate_model(y_test, y_pred, y_prob)\n",
        "        joblib.dump(self, 'facial_recognition_model.pkl')\n",
        "        print(\"Model saved to facial_recognition_model.pkl\")\n",
        "\n",
        "    def evaluate_model(self, y_true, y_pred, y_prob):\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"MODEL EVALUATION RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        # Convert numerical labels back to original strings for report\n",
        "        y_true_labels = self.label_encoder.inverse_transform(y_true)\n",
        "        y_pred_labels = self.label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "        print(\"Accuracy: \", round(accuracy_score(y_true_labels, y_pred_labels), 4))\n",
        "        print(\"F1-Score: \", round(f1_score(y_true_labels, y_pred_labels, average='weighted'), 4))\n",
        "        print(\"Log Loss: \", round(log_loss(y_true_labels, y_prob), 4))\n",
        "        try:\n",
        "            roc_auc = roc_auc_score(pd.get_dummies(y_true_labels), y_prob, multi_class='ovr')\n",
        "            print(\"ROC-AUC:  \", round(roc_auc, 4))\n",
        "        except:\n",
        "            print(\"ROC-AUC:  (not available for single-class test set)\")\n",
        "        print(\"\\nClassification Report:\\n\", classification_report(y_true_labels, y_pred_labels))\n",
        "\n",
        "    def predict(self, X_new):\n",
        "        X_scaled = self.scaler.transform(X_new)\n",
        "        X_selected = self.selector.transform(X_scaled)\n",
        "        X_reduced = self.pca.transform(X_selected)\n",
        "        probs = self.model.predict_proba(X_reduced)\n",
        "        preds = self.model.predict(X_reduced)\n",
        "        conf = np.max(probs, axis=1)\n",
        "\n",
        "        # Convert numerical predictions back to original string labels\n",
        "        predicted_labels = self.label_encoder.inverse_transform(preds)\n",
        "        return predicted_labels, conf"
      ],
      "metadata": {
        "id": "qn8flqdvjI1J"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"image_features.csv\")\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pT9u5m2Ol6mf",
        "outputId": "5a54cc41-1f91-4240-8d57-116333cd3bfa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['filename', 'augmentation', 'width', 'height', 'feature_0', 'feature_1',\n",
            "       'feature_2', 'feature_3', 'feature_4', 'feature_5',\n",
            "       ...\n",
            "       'feature_1802', 'feature_1803', 'feature_1804', 'feature_1805',\n",
            "       'feature_1806', 'feature_1807', 'feature_1808', 'feature_1809',\n",
            "       'feature_1810', 'feature_1811'],\n",
            "      dtype='object', length=1816)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "    # Load dataset\n",
        "    data = pd.read_csv(\"image_features.csv\")\n",
        "\n",
        "    # Extract user identity from filename\n",
        "    data['user_id'] = data['filename'].apply(lambda x: x.split('-')[0])\n",
        "\n",
        "    # Features\n",
        "    feature_cols = [col for col in data.columns if col.startswith('feature_')]\n",
        "    X = data[feature_cols]\n",
        "\n",
        "    y = data['user_id']\n",
        "    le = LabelEncoder()\n",
        "    y_encoded = le.fit_transform(y)\n",
        "\n",
        "    # Initialize and train model\n",
        "    model = FacialRecognitionModel(model_type='hybrid')\n",
        "    model.train(X, y_encoded)\n",
        "\n",
        "    # Predict on first 5 samples\n",
        "    print(\"\\nMaking predictions on first 5 samples...\")\n",
        "    sample = X.head(5)\n",
        "    preds, confs = model.predict(sample)\n",
        "\n",
        "    # Decode predictions back to original user names\n",
        "    preds_labels = le.inverse_transform(preds)\n",
        "\n",
        "    for i, (p, c) in enumerate(zip(preds_labels, confs)):\n",
        "        print(f\"Sample {i+1}: Predicted User ‚Üí {p} | Confidence: {c:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN_4ZW8FkIxW",
        "outputId": "950a57c1-f98c-49b2-89b9-7e516c3516e1"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded dataset with 165 rows and 1812 columns.\n",
            "Balanced dataset: 180 samples after SMOTE.\n",
            "Applying SelectKBest feature selection...\n",
            "Applying PCA dimensionality reduction...\n",
            "\n",
            "============================================================\n",
            "Training Facial Recognition Model (hybrid)\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:44:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:44:50] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:44:52] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:44:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:44:53] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF CV Accuracy: 0.9443 | XGB CV Accuracy: 0.9443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [09:44:54] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "MODEL EVALUATION RESULTS\n",
            "============================================================\n",
            "Accuracy:  0.9167\n",
            "F1-Score:  0.9166\n",
            "Log Loss:  0.1976\n",
            "ROC-AUC:   0.9928\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89         9\n",
            "           1       1.00      0.89      0.94         9\n",
            "           2       0.90      1.00      0.95         9\n",
            "           3       0.89      0.89      0.89         9\n",
            "\n",
            "    accuracy                           0.92        36\n",
            "   macro avg       0.92      0.92      0.92        36\n",
            "weighted avg       0.92      0.92      0.92        36\n",
            "\n",
            "‚úÖ Model saved to facial_recognition_model.pkl\n",
            "\n",
            "üîç Making predictions on first 5 samples...\n",
            "Sample 1: Predicted User ‚Üí Best | Confidence: 1.00\n",
            "Sample 2: Predicted User ‚Üí Best | Confidence: 0.99\n",
            "Sample 3: Predicted User ‚Üí Best | Confidence: 0.99\n",
            "Sample 4: Predicted User ‚Üí Best | Confidence: 0.99\n",
            "Sample 5: Predicted User ‚Üí Best | Confidence: 0.96\n"
          ]
        }
      ]
    }
  ]
}